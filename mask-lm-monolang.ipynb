{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from src.lm_model import AfrikaLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip this cell if you don't plan to push your model to the hub\n",
    "\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure and build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL = 'bert-base-cased'\n",
    "NUM_HIDDENS = 2\n",
    "NUM_ATTENTIONS = 12\n",
    "NUM_TRAIN_EPOCH = 50\n",
    "\n",
    "exec_counter = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_source/lacuna_pos_ner/language_corpus/ibo/ibo.txt'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_src_fnames = glob.glob(\"data_source/lacuna_pos_ner/language_corpus/*/*.txt\")\n",
    "data_src_fnames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 5077.85it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 170.98it/s]\n",
      "Generating train split: 8000 examples [00:00, 673459.22 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 4236.67it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 293.33it/s]\n",
      "Generating train split: 13128 examples [00:00, 735543.99 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 5210.32it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 345.32it/s]\n",
      "Generating train split: 4841 examples [00:00, 483478.00 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 3175.10it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 327.35it/s]\n",
      "Generating train split: 3006 examples [00:00, 403652.24 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 5817.34it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 512.81it/s]\n",
      "Generating train split: 3360 examples [00:00, 819352.41 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 5262.61it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 442.44it/s]\n",
      "Generating train split: 6618 examples [00:00, 640424.15 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 4604.07it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 294.54it/s]\n",
      "Generating train split: 3516 examples [00:00, 315198.09 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 3890.82it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 357.27it/s]\n",
      "Generating train split: 2979 examples [00:00, 526608.15 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 5127.51it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 386.86it/s]\n",
      "Generating train split: 2026 examples [00:00, 494366.16 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 4219.62it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 419.98it/s]\n",
      "Generating train split: 6378 examples [00:00, 529162.30 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 7943.76it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 584.90it/s]\n",
      "Generating train split: 8000 examples [00:00, 1177844.43 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 3744.91it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 330.13it/s]\n",
      "Generating train split: 7038 examples [00:00, 619923.38 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 6250.83it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 455.61it/s]\n",
      "Generating train split: 7554 examples [00:00, 614240.87 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 3236.35it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 284.75it/s]\n",
      "Generating train split: 7266 examples [00:00, 591074.73 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 4092.00it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 437.68it/s]\n",
      "Generating train split: 7999 examples [00:00, 516395.84 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 4202.71it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 320.86it/s]\n",
      "Generating train split: 7974 examples [00:00, 833072.96 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 5882.61it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 504.79it/s]\n",
      "Generating train split: 8047 examples [00:00, 768495.74 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 5262.61it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 413.03it/s]\n",
      "Generating train split: 9834 examples [00:00, 876230.23 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 4096.00it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 384.62it/s]\n",
      "Generating train split: 3110 examples [00:00, 436365.89 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 4975.45it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 584.08it/s]\n",
      "Generating train split: 22 examples [00:00, 10115.62 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 5029.14it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 360.49it/s]\n",
      "Generating train split: 3708 examples [00:00, 451975.57 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 2557.50it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 231.84it/s]\n",
      "Generating train split: 3869 examples [00:00, 613224.58 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 9118.05it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 576.77it/s]\n",
      "Generating train split: 9834 examples [00:00, 1249410.40 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 5622.39it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 547.92it/s]\n",
      "Generating train split: 8 examples [00:00, 4228.13 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 3953.16it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 433.07it/s]\n",
      "Generating train split: 11035 examples [00:00, 631004.02 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 6364.65it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 422.69it/s]\n",
      "Generating train split: 3868 examples [00:00, 723781.75 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 5269.23it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 448.40it/s]\n",
      "Generating train split: 5507 examples [00:00, 367967.12 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 9177.91it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 517.30it/s]\n",
      "Generating train split: 8313 examples [00:00, 1980193.61 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 3908.95it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 309.20it/s]\n",
      "Generating train split: 7911 examples [00:00, 282989.96 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 8338.58it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 144.19it/s]\n",
      "Generating train split: 5135 examples [00:00, 410078.85 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 5683.34it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 53.57it/s]\n",
      "Generating train split: 4140 examples [00:00, 370527.88 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 5584.96it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 420.73it/s]\n",
      "Generating train split: 802 examples [00:00, 289013.82 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 5084.00it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 504.55it/s]\n",
      "Generating train split: 8000 examples [00:00, 611860.54 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 2863.01it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 210.92it/s]\n",
      "Generating train split: 8954 examples [00:00, 748406.73 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "n_params = {}\n",
    "for fname in data_src_fnames:\n",
    "    lang = os.path.basename(fname).split(\".\")[0]\n",
    "    model = AfrikaLM(fname, NUM_HIDDENS, NUM_ATTENTIONS, BASE_MODEL)\n",
    "    models[lang] = model\n",
    "    n_params[lang] = sum(p.numel() for p in model.model.parameters() if p.requires_grad)\n",
    "\n",
    "n_params = pd.Series(n_params)\n",
    "n_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=4): 100%|██████████| 6400/6400 [00:01<00:00, 3959.05 examples/s]\n",
      "Map (num_proc=4): 100%|██████████| 1600/1600 [00:01<00:00, 1298.41 examples/s]\n",
      "Map (num_proc=4): 100%|██████████| 6400/6400 [00:02<00:00, 2612.28 examples/s]\n",
      "Map (num_proc=4): 100%|██████████| 1600/1600 [00:01<00:00, 1279.60 examples/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      " 50%|█████     | 500/1000 [02:51<02:45,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6531, 'learning_rate': 1e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 50%|█████     | 500/1000 [03:03<02:45,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.47823724150657654, 'eval_runtime': 11.5799, 'eval_samples_per_second': 172.541, 'eval_steps_per_second': 10.795, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [05:41<00:00,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4678, 'learning_rate': 0.0, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "100%|██████████| 1000/1000 [05:51<00:00,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.45542100071907043, 'eval_runtime': 10.3931, 'eval_samples_per_second': 192.244, 'eval_steps_per_second': 12.027, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [05:52<00:00,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 352.3637, 'train_samples_per_second': 45.408, 'train_steps_per_second': 2.838, 'train_loss': 0.5604309387207032, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for lang, model in models.items():\n",
    "    print(\"*******************\\nTraining {lang} model\\n********************\")\n",
    "    model.train_model(f\"models/afrikalm-{lang}\", num_train_epochs=NUM_TRAIN_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:10<00:00, 12.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 1.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "perplexity = {}\n",
    "for lang, model in models.items():\n",
    "    print(\"*******************\\nEvaluating {lang} model\\n********************\")\n",
    "    ppl = model.evaluate()\n",
    "    perplexity[lang] = ppl \n",
    "\n",
    "perplexity = pd.Series(perplexity)\n",
    "perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = \"bịara\"\n",
    "text = \"Onye ọgba ama ahụ kwuru sị na ndị uweojii ngalaba ahụ [MASK] nwụchikọọ ya mgbe a gwara ha maka ya.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.16119235754013062,\n",
       "  'token': 58,\n",
       "  'token_str': 'a',\n",
       "  'sequence': 'Onye ọgba ama ahụ kwuru sị na ndị uweojii ngalaba ahụ a nwụchikọọ ya mgbe a gwara ha maka ya.'},\n",
       " {'score': 0.09059896320104599,\n",
       "  'token': 62,\n",
       "  'token_str': 'e',\n",
       "  'sequence': 'Onye ọgba ama ahụ kwuru sị na ndị uweojii ngalaba ahụ e nwụchikọọ ya mgbe a gwara ha maka ya.'},\n",
       " {'score': 0.07759804278612137,\n",
       "  'token': 71,\n",
       "  'token_str': 'n',\n",
       "  'sequence': 'Onye ọgba ama ahụ kwuru sị na ndị uweojii ngalaba ahụ n nwụchikọọ ya mgbe a gwara ha maka ya.'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[\"ibo\"].predict(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "afrika-pos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
