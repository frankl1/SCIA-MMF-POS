{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers accelerate datasets evaluate torch torchaudio torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from src.lm_model import AfrikaLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3dceb2899844d28b50c283ff255521b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# skip this cell if you don't plan to push your model to the hub\n",
    "\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure and build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL = 'bert-base-cased'\n",
    "NUM_HIDDENS = 2\n",
    "NUM_ATTENTIONS = 12\n",
    "NUM_TRAIN_EPOCH = 1\n",
    "\n",
    "exec_counter = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_source/lacuna_pos_ner/language_corpus/ibo/ibo.txt'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_src_fnames = glob.glob(\"data_source/lacuna_pos_ner/language_corpus/*/*.txt\")\n",
    "data_src_fnames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf15b5727ea44865b10b5ca773a74cf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = AfrikaLM(data_src_fnames, NUM_HIDDENS, NUM_ATTENTIONS, BASE_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Params: 37462084\n"
     ]
    }
   ],
   "source": [
    "n_params = sum(p.numel() for p in model.model.parameters() if p.requires_grad)\n",
    "print(\"#Params:\", n_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "322be20b2f4549cd8a7254f40a4b6a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/170305 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1073 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1144 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (811 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (541 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cd6e59df5e44694a030924c1565358d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/42577 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (529 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (666 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc3ca29dbd264d9c91e36a6e84289ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/170305 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8266541423204882b54512aa3a12e31a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/42577 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Token is required (write-access action) but no token found. You need to provide a token or be logged in to Hugging Face with `huggingface-cli login` or `huggingface_hub.login`. See https://huggingface.co/settings/tokens.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/bapa/Codes/Sangkak-Challenge-IA/mask-lm-multilang.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/bapa/Codes/Sangkak-Challenge-IA/mask-lm-multilang.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mtrain_model(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmodels/afrikalm-multilang\u001b[39;49m\u001b[39m\"\u001b[39;49m, num_train_epochs\u001b[39m=\u001b[39;49mNUM_TRAIN_EPOCH)\n",
      "File \u001b[0;32m~/Codes/Sangkak-Challenge-IA/src/lm_model.py:113\u001b[0m, in \u001b[0;36mAfrikaLM.train_model\u001b[0;34m(self, output_dir, learning_rate, num_train_epochs, weight_decay, batch_size, validate_on_test, push_to_hub)\u001b[0m\n\u001b[1;32m     96\u001b[0m lm_dataset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_lm_dataset()\n\u001b[1;32m     98\u001b[0m training_args \u001b[39m=\u001b[39m TrainingArguments(\n\u001b[1;32m     99\u001b[0m     output_dir\u001b[39m=\u001b[39moutput_dir,\n\u001b[1;32m    100\u001b[0m     learning_rate\u001b[39m=\u001b[39mlearning_rate,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    110\u001b[0m     push_to_hub\u001b[39m=\u001b[39mpush_to_hub\n\u001b[1;32m    111\u001b[0m )\n\u001b[0;32m--> 113\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m    114\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel,\n\u001b[1;32m    115\u001b[0m     args\u001b[39m=\u001b[39;49mtraining_args,\n\u001b[1;32m    116\u001b[0m     train_dataset\u001b[39m=\u001b[39;49mlm_dataset[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    117\u001b[0m     eval_dataset\u001b[39m=\u001b[39;49mlm_dataset[\u001b[39m'\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    118\u001b[0m     tokenizer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenizer,\n\u001b[1;32m    119\u001b[0m     data_collator\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_collator\n\u001b[1;32m    120\u001b[0m )\n\u001b[1;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/miniconda3/envs/afrika-pos/lib/python3.10/site-packages/transformers/trainer.py:568\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhub_model_id \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpush_to_hub:\n\u001b[0;32m--> 568\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minit_hf_repo()\n\u001b[1;32m    569\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mshould_save:\n\u001b[1;32m    570\u001b[0m     os\u001b[39m.\u001b[39mmakedirs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39moutput_dir, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/afrika-pos/lib/python3.10/site-packages/transformers/trainer.py:3533\u001b[0m, in \u001b[0;36mTrainer.init_hf_repo\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3530\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3531\u001b[0m     repo_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mhub_model_id\n\u001b[0;32m-> 3533\u001b[0m repo_url \u001b[39m=\u001b[39m create_repo(repo_name, token\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49mhub_token, private\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49mhub_private_repo, exist_ok\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   3534\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhub_model_id \u001b[39m=\u001b[39m repo_url\u001b[39m.\u001b[39mrepo_id\n\u001b[1;32m   3535\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpush_in_progress \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/afrika-pos/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/afrika-pos/lib/python3.10/site-packages/huggingface_hub/hf_api.py:2542\u001b[0m, in \u001b[0;36mHfApi.create_repo\u001b[0;34m(self, repo_id, token, private, repo_type, exist_ok, space_sdk, space_hardware, space_storage, space_sleep_time, space_secrets, space_variables)\u001b[0m\n\u001b[1;32m   2538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_lfsmultipartthresh\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   2539\u001b[0m     \u001b[39m# Testing purposes only.\u001b[39;00m\n\u001b[1;32m   2540\u001b[0m     \u001b[39m# See https://github.com/huggingface/huggingface_hub/pull/733/files#r820604472\u001b[39;00m\n\u001b[1;32m   2541\u001b[0m     json[\u001b[39m\"\u001b[39m\u001b[39mlfsmultipartthresh\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lfsmultipartthresh  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 2542\u001b[0m headers \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_hf_headers(token\u001b[39m=\u001b[39;49mtoken, is_write_action\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   2543\u001b[0m r \u001b[39m=\u001b[39m get_session()\u001b[39m.\u001b[39mpost(path, headers\u001b[39m=\u001b[39mheaders, json\u001b[39m=\u001b[39mjson)\n\u001b[1;32m   2545\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/afrika-pos/lib/python3.10/site-packages/huggingface_hub/hf_api.py:5719\u001b[0m, in \u001b[0;36mHfApi._build_hf_headers\u001b[0;34m(self, token, is_write_action, library_name, library_version, user_agent)\u001b[0m\n\u001b[1;32m   5716\u001b[0m \u001b[39mif\u001b[39;00m token \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5717\u001b[0m     \u001b[39m# Cannot do `token = token or self.token` as token can be `False`.\u001b[39;00m\n\u001b[1;32m   5718\u001b[0m     token \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoken\n\u001b[0;32m-> 5719\u001b[0m \u001b[39mreturn\u001b[39;00m build_hf_headers(\n\u001b[1;32m   5720\u001b[0m     token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m   5721\u001b[0m     is_write_action\u001b[39m=\u001b[39;49mis_write_action,\n\u001b[1;32m   5722\u001b[0m     library_name\u001b[39m=\u001b[39;49mlibrary_name \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlibrary_name,\n\u001b[1;32m   5723\u001b[0m     library_version\u001b[39m=\u001b[39;49mlibrary_version \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlibrary_version,\n\u001b[1;32m   5724\u001b[0m     user_agent\u001b[39m=\u001b[39;49muser_agent \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49muser_agent,\n\u001b[1;32m   5725\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/afrika-pos/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/afrika-pos/lib/python3.10/site-packages/huggingface_hub/utils/_headers.py:122\u001b[0m, in \u001b[0;36mbuild_hf_headers\u001b[0;34m(token, is_write_action, library_name, library_version, user_agent)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39m# Get auth token to send\u001b[39;00m\n\u001b[1;32m    121\u001b[0m token_to_send \u001b[39m=\u001b[39m get_token_to_send(token)\n\u001b[0;32m--> 122\u001b[0m _validate_token_to_send(token_to_send, is_write_action\u001b[39m=\u001b[39;49mis_write_action)\n\u001b[1;32m    124\u001b[0m \u001b[39m# Combine headers\u001b[39;00m\n\u001b[1;32m    125\u001b[0m headers \u001b[39m=\u001b[39m {\n\u001b[1;32m    126\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39muser-agent\u001b[39m\u001b[39m\"\u001b[39m: _http_user_agent(\n\u001b[1;32m    127\u001b[0m         library_name\u001b[39m=\u001b[39mlibrary_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m     )\n\u001b[1;32m    131\u001b[0m }\n",
      "File \u001b[0;32m~/miniconda3/envs/afrika-pos/lib/python3.10/site-packages/huggingface_hub/utils/_headers.py:172\u001b[0m, in \u001b[0;36m_validate_token_to_send\u001b[0;34m(token, is_write_action)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[39mif\u001b[39;00m is_write_action:\n\u001b[1;32m    171\u001b[0m     \u001b[39mif\u001b[39;00m token \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    173\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mToken is required (write-access action) but no token found. You need\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    174\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m to provide a token or be logged in to Hugging Face with\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    175\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m `huggingface-cli login` or `huggingface_hub.login`. See\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    176\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m https://huggingface.co/settings/tokens.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    177\u001b[0m         )\n\u001b[1;32m    178\u001b[0m     \u001b[39mif\u001b[39;00m token\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mapi_org\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    179\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    180\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mYou must use your personal account token for write-access methods. To\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    181\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m generate a write-access token, go to\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    182\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m https://huggingface.co/settings/tokens\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    183\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Token is required (write-access action) but no token found. You need to provide a token or be logged in to Hugging Face with `huggingface-cli login` or `huggingface_hub.login`. See https://huggingface.co/settings/tokens."
     ]
    }
   ],
   "source": [
    "model.train_model(f\"models/afrikalm-multilang\", num_train_epochs=NUM_TRAIN_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:10<00:00, 12.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 1.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ppl = model.evaluate()\n",
    "print(f\"Perplexity: {ppl:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = \"bịara\"\n",
    "text = \"Onye ọgba ama ahụ kwuru sị na ndị uweojii ngalaba ahụ [MASK] nwụchikọọ ya mgbe a gwara ha maka ya.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.16119235754013062,\n",
       "  'token': 58,\n",
       "  'token_str': 'a',\n",
       "  'sequence': 'Onye ọgba ama ahụ kwuru sị na ndị uweojii ngalaba ahụ a nwụchikọọ ya mgbe a gwara ha maka ya.'},\n",
       " {'score': 0.09059896320104599,\n",
       "  'token': 62,\n",
       "  'token_str': 'e',\n",
       "  'sequence': 'Onye ọgba ama ahụ kwuru sị na ndị uweojii ngalaba ahụ e nwụchikọọ ya mgbe a gwara ha maka ya.'},\n",
       " {'score': 0.07759804278612137,\n",
       "  'token': 71,\n",
       "  'token_str': 'n',\n",
       "  'sequence': 'Onye ọgba ama ahụ kwuru sị na ndị uweojii ngalaba ahụ n nwụchikọọ ya mgbe a gwara ha maka ya.'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "afrika-pos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
